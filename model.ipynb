{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import fractional_matrix_power\n",
    "def gcn(A):\n",
    "    I = np.identity(A.shape[0]) #create Identity Matrix of A\n",
    "    A_hat = A + I #add self-loop to A\n",
    "    D = np.diag(np.sum(A_hat, axis=0)) #create Degree Matrix of A\n",
    "    D_half_norm = fractional_matrix_power(D, -0.5) #calculate D to the power of -0.5\n",
    "    eq = D_half_norm.dot(A_hat).dot(D_half_norm)\n",
    "    return eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self, A):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 12.\n",
    "        g_out = 12\n",
    "        self.A = gcn(A)\n",
    "        self.double_a = gcn(np.matmul(self.A, self.A))\n",
    "        self.A = torch.from_numpy(self.A).float()\n",
    "        self.double_a = torch.from_numpy(self.double_a).float()\n",
    "        self.layer_1 = nn.Linear(148, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(16 * 64, 1) \n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(148, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "        )\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(12, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(12, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 16),\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "    def forward(self, inputs):\n",
    "      #  x = self.encode(inputs)\n",
    "        x = self.encode(inputs)\n",
    "        two = torch.matmul(self.A, np.transpose(inputs))\n",
    "        two = np.transpose(two)\n",
    "        two = self.encode(two)\n",
    "        three = torch.matmul(self.double_a, np.transpose(inputs))\n",
    "        three = np.transpose(three)\n",
    "        three = self.encode(three)\n",
    "        x = torch.stack((x, two, three), dim = 2)\n",
    "        x = self.lin(x).flatten(start_dim = 1)\n",
    "        x = self.layer_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mihir/Downloads/gae-master-2/gae/input_data.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  i[1]['label'] = l\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsample.callbacks import EarlyStopping\n",
    "\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "from input_data import load_data\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import torch.optim as optim\n",
    "A, f, labels, total = load_data()\n",
    "A = A.toarray()\n",
    "f = f.to_numpy()\n",
    "f = np.transpose(f)\n",
    "labels = np.array(labels)\n",
    "labels = np.expand_dims(labels, axis=1)\n",
    "tensor_input = torch.from_numpy(f).float()\n",
    "tensor_label = torch.Tensor(labels).float()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(index, k_fold, x, y):\n",
    "    size = np.shape(x)[0]\n",
    "    idx = range(size)\n",
    "    r = range(0, int(size/k_fold))\n",
    "    r = [i + index * int(size/k_fold) for i in r]\n",
    "    idx = list(set(idx) - set(r))\n",
    "    x_mb     = x[idx].astype(float)\n",
    "    y_mb = y[idx].astype(float) \n",
    "    return x_mb, y_mb\n",
    "def get_missing_data(index, k_fold, x, y):\n",
    "    size = np.shape(x)[0]\n",
    "    idx = range(size)\n",
    "    r = range(0, int(size/k_fold))\n",
    "    r = [i + index * int(size/k_fold) for i in r]\n",
    "    idx = list(set(r))\n",
    "    x_mb     = x[idx].astype(float)\n",
    "    y_mb     = y[idx].astype(float)\n",
    "    return x_mb, y_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = split_data(0, 5, f, labels)\n",
    "x_test, y_test = get_missing_data(0, 5, f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "from input_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8830815298761399\n",
      "Accuracy:0.8046070460704606\n",
      "Accuracy:0.7848923785027752\n",
      "Accuracy:0.8415411748745083\n",
      "Accuracy:0.7893366228070176\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "k_folds = 5\n",
    "total_acc = 0\n",
    "for i in range(k_folds):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    model = binaryClassification(A)\n",
    "    loss = criterion\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    model.train()\n",
    "    f_train, label_train = split_data(i, k_folds, f, labels)\n",
    "    f_test, label_test = get_missing_data(i, k_folds, f, labels)\n",
    "    train_data = trainData(torch.from_numpy(f_train).float(), torch.Tensor(label_train).float())\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=300, shuffle=True)\n",
    "    for e in range(1, 100):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        test_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            acc = binary_acc(y_pred, y_batch)\n",
    "\n",
    "            test_acc += binary_acc(model(torch.Tensor(f_test).float()), torch.tensor(label_test).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        if(epoch_loss/len(train_loader)<=0.5):\n",
    "            break\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}|Test:{test_acc/len(train_loader):.5f}')\n",
    "    print(\"Accuracy:\" + str(roc_auc_score(label_test,torch.sigmoid(model(torch.Tensor(f_test).float())).detach().numpy())))\n",
    "    total_acc += (roc_auc_score(label_test,torch.sigmoid(model(torch.Tensor(f_test).float())).detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8206917504261803\n"
     ]
    }
   ],
   "source": [
    "print(total_acc/k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
